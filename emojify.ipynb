{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import emoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as  pd\n",
    "train = pd.read_csv('data/emojify/train_emoji.csv',names=[\"0\",\"1\",\"2\",\"3\"])\n",
    "test = pd.read_csv('data/emojify/test_emoji.csv',names=[\"0\",\"1\",\"2\",\"3\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "emoji_dictionary={0:\"\\u2764\\uFE0F\",1:\":baseball:\",2:\":smile:\",3:\":disappointed:\",4:\":fork_and_knife:\"}\n",
    "def convert_to_emoji(label):\n",
    "    return emoji.emojize(emoji_dictionary[label],use_aliases=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(y,c):\n",
    "    y=np.eye(c)[y.reshape(-1)]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_glove_vecs(glove_file):\n",
    "    with open(glove_file,'r',encoding=\"utf8\") as f:\n",
    "        word_to_vec={}\n",
    "        word_to_index={}\n",
    "        index_to_word={}\n",
    "        word=set()\n",
    "        for line in f:\n",
    "            line=line.strip().split()\n",
    "            curr_word=line[0]\n",
    "            word.add(curr_word)\n",
    "            word_to_vec[curr_word]=np.array(line[1:],dtype=np.float64)\n",
    "        i=1\n",
    "        for w in sorted(word):\n",
    "            word_to_index[w]=i\n",
    "            index_to_word[i]=w\n",
    "            i=i+1\n",
    "    return  word_to_index,index_to_word,word_to_vec      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence_to_avg(sentence, word_to_vec_map):\n",
    "    # Step 1: Split sentence into list of lower case words (‚âà 1 line)\n",
    "    words = sentence.lower().split()\n",
    "\n",
    "    # Initialize the average word vector, should have the same shape as your word vectors.\n",
    "    avg = np.zeros_like(word_to_vec_map[words[0]])\n",
    "    \n",
    "    # Step 2: average the word vectors. You can loop over the words in the list \"words\".\n",
    "    total = 0\n",
    "    for w in words:\n",
    "        total += word_to_vec_map[w]\n",
    "    avg = total/len(words)\n",
    "    \n",
    "    return avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "    e_x = np.exp(x - np.max(x))\n",
    "    return e_x / e_x.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,y,W,b,word_to_vec_map):\n",
    "    m=X.shape[0]\n",
    "    prediction=np.zeros((m,1))\n",
    "    for i in range(m):\n",
    "        avg=sentence_to_avg(X[i],word_to_vec_map)\n",
    "        Z = np.dot(W, avg) + b\n",
    "        A = softmax(Z)\n",
    "        prediction[i] = np.argmax(A) \n",
    "    print(\"Accuracy: \"  + str(np.mean((prediction[:] == y.reshape(y.shape[0],1)[:]))))    \n",
    "    return prediction\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_actu, y_pred, title='Confusion matrix'):\n",
    "    \n",
    "    df_confusion = pd.crosstab(y_actu, y_pred.reshape(y_pred.shape[0],), rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "    \n",
    "    df_conf_norm = df_confusion / df_confusion.sum(axis=1)\n",
    "    \n",
    "    plt.matshow(df_confusion) # imshow\n",
    "    #plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(df_confusion.columns))\n",
    "    plt.xticks(tick_marks, df_confusion.columns, rotation=45)\n",
    "    plt.yticks(tick_marks, df_confusion.index)\n",
    "    #plt.tight_layout()\n",
    "    plt.ylabel(df_confusion.index.name)\n",
    "    plt.xlabel(df_confusion.columns.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=np.array(train.loc[:,\"0\"])\n",
    "y_train=np.array(train.loc[:,\"1\"])\n",
    "X_test=np.array(test.loc[:,\"0\"])\n",
    "y_test=np.array(test.loc[:,\"1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the maximum length of a string in X_train\n",
    "max_len_train=len(max(X_train,key=len).split())\n",
    "#find the maximum length of a string in X_test\n",
    "max_len_test=len(max(X_test,key=len).split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "never talk to me again üòû\n",
      "I am proud of your achievements üòÑ\n",
      "It is the worst day in my life üòû\n",
      "Miss you so much ‚ù§Ô∏è\n",
      "food is life üç¥\n",
      "I love you mum ‚ù§Ô∏è\n",
      "Stop saying bullshit üòû\n",
      "congratulations on your acceptance üòÑ\n",
      "The assignment is too long  üòû\n",
      "I want to go play ‚öæ\n"
     ]
    }
   ],
   "source": [
    "#display  sentences from X_train and corresponding labels from Y_train.\n",
    "for idx in range(10):\n",
    "    print(X_train[idx], convert_to_emoji(y_train[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_oh_train = convert_to_one_hot(y_train, c= 5)\n",
    "y_oh_test = convert_to_one_hot(y_test, c = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 'I missed you' has label index 1, which is emoji ‚öæ\n",
      "Label index 1 in one-hot encoding format is [0. 1. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "idx = 25\n",
    "print(f\"Sentence '{X_train[50]}' has label index {y_train[idx]}, which is emoji {convert_to_emoji(y_train[idx])}\", )\n",
    "print(f\"Label index {y_train[idx]} in one-hot encoding format is {y_oh_train[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_to_index, index_to_word, word_to_vec_map = read_glove_vecs(r'C:\\Users\\RN7\\data\\emojify/glove.6B.50d.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the index of fruit in the vocabulary is 154530\n",
      "the 289846th word in the vocabulary is potatos\n"
     ]
    }
   ],
   "source": [
    "word = \"fruit\"\n",
    "idx = 289846\n",
    "print(\"the index of\", word, \"in the vocabulary is\", word_to_index[word])\n",
    "print(\"the\", str(idx) + \"th word in the vocabulary is\", index_to_word[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X, Y, word_to_vec_map, learning_rate = 0.01, num_iterations = 400):\n",
    "    \n",
    "    np.random.seed(1)\n",
    "\n",
    "    m = Y.shape[0]                          # number of training examples\n",
    "    n_y = 5                                 # number of classes  \n",
    "    n_h = 50                                # dimensions of the GloVe vectors \n",
    "    \n",
    "    # Initialize parameters using Xavier initialization\n",
    "    W = np.random.randn(n_y, n_h) / np.sqrt(n_h)\n",
    "    b = np.zeros((n_y,))\n",
    "    \n",
    "    # Convert Y to Y_onehot with n_y classes\n",
    "    Y_oh = convert_to_one_hot(Y, c= n_y) \n",
    "    \n",
    "    # Optimization loop\n",
    "    for t in range(num_iterations): # Loop over the number of iterations\n",
    "        for i in range(m):          # Loop over the training examples\n",
    "            \n",
    "            # Average the word vectors of the words from the i'th training example\n",
    "            avg = sentence_to_avg(X[i], word_to_vec_map)\n",
    "\n",
    "            # Forward propagate the avg through the softmax layer\n",
    "            z = np.dot(W,avg)+b\n",
    "            a = softmax(z)\n",
    "\n",
    "            # Compute cost using the i'th training label's one hot representation and \"A\" (the output of the softmax)\n",
    "            cost = -np.sum(np.dot(Y_oh[i],np.log(a)))\n",
    "            ### END CODE HERE ###\n",
    "            \n",
    "            # Compute gradients \n",
    "            dz = a - Y_oh[i]\n",
    "            dW = np.dot(dz.reshape(n_y,1), avg.reshape(1, n_h))\n",
    "            db = dz\n",
    "\n",
    "            # Update parameters with Stochastic Gradient Descent\n",
    "            W = W - learning_rate * dW\n",
    "            b = b - learning_rate * db\n",
    "        \n",
    "        if t % 100 == 0:\n",
    "            print(\"Epoch: \" + str(t) + \" --- cost = \" + str(cost))\n",
    "            pred = predict(X, Y, W, b, word_to_vec_map) #predict is defined in emo_utils.py\n",
    "\n",
    "    return pred, W, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0 --- cost = 1.9520498812810072\n",
      "Accuracy: 0.3484848484848485\n",
      "Epoch: 100 --- cost = 0.07971818726014807\n",
      "Accuracy: 0.9318181818181818\n",
      "Epoch: 200 --- cost = 0.04456369243681402\n",
      "Accuracy: 0.9545454545454546\n",
      "Epoch: 300 --- cost = 0.03432267378786059\n",
      "Accuracy: 0.9696969696969697\n",
      "[[3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [2.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [0.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [0.]\n",
      " [1.]\n",
      " [2.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [3.]\n",
      " [2.]\n",
      " [2.]\n",
      " [2.]\n",
      " [4.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [1.]\n",
      " [2.]\n",
      " [1.]\n",
      " [1.]\n",
      " [3.]\n",
      " [1.]\n",
      " [0.]\n",
      " [4.]\n",
      " [0.]\n",
      " [3.]\n",
      " [3.]\n",
      " [4.]\n",
      " [4.]\n",
      " [1.]\n",
      " [4.]\n",
      " [3.]\n",
      " [0.]\n",
      " [2.]]\n"
     ]
    }
   ],
   "source": [
    "pred, W, b = model(X_train, y_train, word_to_vec_map)\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Accuracy: 0.9772727272727273\n",
      "Test set:\n",
      "Accuracy: 0.8571428571428571\n"
     ]
    }
   ],
   "source": [
    "print(\"Training set:\")\n",
    "pred_train = predict(X_train, y_train, W, b, word_to_vec_map)\n",
    "print('Test set:')\n",
    "pred_test = predict(X_test, y_test, W, b, word_to_vec_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "confusion matrix is given below:\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           ‚ù§Ô∏è    ‚öæ    üòÑ    üòû   üç¥\n"
     ]
    }
   ],
   "source": [
    "#confusion matrix of Random forest Classifier\n",
    "print(\"confusion matrix is given below:\")\n",
    "matrix=confusion_matrix(y_test,pred_test)\n",
    "sns.heatmap(matrix, annot=True, fmt='.2f')\n",
    "plt.ylabel('True class')\n",
    "plt.xlabel('Predicted class')\n",
    "plt.show()\n",
    "print('           '+ convert_to_emoji(0)+ '    ' + convert_to_emoji(1) + '    ' +  convert_to_emoji(2)+ '    ' + convert_to_emoji(3)+'   ' + convert_to_emoji(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model using LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(0)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Input, Dropout, LSTM, Activation\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence\n",
    "from keras.initializers import glorot_uniform\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentences_to_indices(X, word_to_index, max_len):\n",
    "    \n",
    "    m = X.shape[0]                                   #\n",
    "    X_indices = np.zeros((m,max_len))\n",
    "    \n",
    "    for i in range(m):                              \n",
    "        \n",
    "        sentence_words = [i.lower() for i in X[i].split()]\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "       \n",
    "        for w in sentence_words:\n",
    "            X_indices[i, j] = word_to_index[w]\n",
    "            j = j+1\n",
    "            \n",
    "    \n",
    "    return X_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrained_embedding_layer(word_to_vec_map, word_to_index):\n",
    "    \n",
    "    vocab_len = len(word_to_index) + 1                 # extra 1 for unknown word \n",
    "    emb_dim = word_to_vec_map[\"cucumber\"].shape[0]      # define dimensionality of your GloVe word vectors (= 50)\n",
    "    emb_matrix = np.zeros((vocab_len,emb_dim))\n",
    "    for word, idx in word_to_index.items():\n",
    "        emb_matrix[idx, :] = word_to_vec_map[word]\n",
    "    # Define Keras embedding layer with the correct input and output sizes\n",
    "    # Make it non-trainable.\n",
    "    embedding_layer = Embedding(vocab_len,emb_dim)\n",
    "\n",
    "    # Build the embedding layer, it is required before setting the weights of the embedding layer. \n",
    "    embedding_layer.build((None,)) #  \"None\".is for non_trainable\n",
    "    \n",
    "    # Set the weights of the embedding layer to the embedding matrix. Your layer is now pretrained.\n",
    "    embedding_layer.set_weights([emb_matrix])\n",
    "    \n",
    "    return embedding_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build embedding layer\n",
    "\n",
    "* Let's build the `Embedding()` layer in Keras, using pre-trained word vectors. \n",
    "* The embedding layer takes as input a list of word indices.\n",
    "    * `sentences_to_indices()` creates these word indices.\n",
    "* The embedding layer will return the word embeddings for a sentence. \n",
    "\n",
    "**Exercise**: Implement `pretrained_embedding_layer()` with these steps:\n",
    "1. Initialize the embedding matrix as a numpy array of zeros.\n",
    "    * The embedding matrix has a row for each unique word in the vocabulary.\n",
    "        * There is one additional row to handle \"unknown\" words.\n",
    "        * So vocab_len is the number of unique words plus one.\n",
    "    * Each row will store the vector representation of one word. \n",
    "        * For example, one row may be 50 positions long if using GloVe word vectors.\n",
    "    * In the code below, `emb_dim` represents the length of a word embedding.\n",
    "2. Fill in each row of the embedding matrix with the vector representation of a word\n",
    "    * Each word in `word_to_index` is a string.\n",
    "    * word_to_vec_map is a dictionary where the keys are strings and the values are the word vectors.\n",
    "3. Define the Keras embedding layer. \n",
    "    * Use [Embedding()](https://keras.io/layers/embeddings/). \n",
    "    * The input dimension is equal to the vocabulary length (number of unique words plus one).\n",
    "    * The output dimension is equal to the number of positions in a word embedding.\n",
    "    * Make this layer's embeddings fixed.\n",
    "        * If you were to set `trainable = True`, then it will allow the optimization algorithm to modify the values of the word embeddings.\n",
    "        * In this case, we don't want the model to modify the word embeddings.\n",
    "4. Set the embedding weights to be equal to the embedding matrix.\n",
    "    * Note that this is part of the code is already completed for you and does not need to be modified. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Emojify(input_shape, word_to_vec_map, word_to_index):\n",
    "    \n",
    "    sentence_indices = Input(input_shape, dtype='int32')\n",
    "    \n",
    "    embedding_layer = pretrained_embedding_layer(word_to_vec_map, word_to_index)\n",
    "    \n",
    "    embeddings = embedding_layer(sentence_indices)  \n",
    "    \n",
    "    X = LSTM(128, return_sequences = True)(embeddings)\n",
    "\n",
    "    X = Dropout(0.5)(X)\n",
    "   \n",
    "    X = LSTM(128, return_sequences=False)(X)\n",
    " \n",
    "    X = Dropout(0.5)(X)\n",
    " \n",
    "    X = Dense(5)(X)\n",
    "    \n",
    "    X = Activation('softmax')(X)\n",
    "    \n",
    "    # Create Model instance which converts sentence_indices into X.\n",
    "    model = Model(inputs=sentence_indices, outputs=X)\n",
    "    \n",
    "    ### END CODE HERE ###\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "embedding_3 (Embedding)      (None, 10, 50)            20000050  \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 10, 128)           91648     \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 10, 128)           0         \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 645       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 20,223,927\n",
      "Trainable params: 20,223,927\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Emojify((max_len_train,), word_to_vec_map, word_to_index)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\RN7\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:433: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "132/132 [==============================] - 3s 26ms/step - loss: 1.5914 - accuracy: 0.2803\n",
      "Epoch 2/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 1.5306 - accuracy: 0.3030\n",
      "Epoch 3/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 1.4706 - accuracy: 0.3712\n",
      "Epoch 4/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 1.4318 - accuracy: 0.4470\n",
      "Epoch 5/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 1.2990 - accuracy: 0.5758\n",
      "Epoch 6/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 1.1853 - accuracy: 0.5833\n",
      "Epoch 7/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 1.0255 - accuracy: 0.6439\n",
      "Epoch 8/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.8645 - accuracy: 0.6818\n",
      "Epoch 9/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.8270 - accuracy: 0.6970\n",
      "Epoch 10/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.6487 - accuracy: 0.8182\n",
      "Epoch 11/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.5897 - accuracy: 0.8106\n",
      "Epoch 12/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.4600 - accuracy: 0.8409\n",
      "Epoch 13/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 0.3658 - accuracy: 0.8712\n",
      "Epoch 14/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 0.3459 - accuracy: 0.9015\n",
      "Epoch 15/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.3361 - accuracy: 0.8636\n",
      "Epoch 16/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.7635 - accuracy: 0.7576\n",
      "Epoch 17/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.6602 - accuracy: 0.7879\n",
      "Epoch 18/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.4176 - accuracy: 0.8258\n",
      "Epoch 19/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.4760 - accuracy: 0.8333\n",
      "Epoch 20/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.3228 - accuracy: 0.9091\n",
      "Epoch 21/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.2848 - accuracy: 0.8939\n",
      "Epoch 22/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.2488 - accuracy: 0.9394\n",
      "Epoch 23/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.2473 - accuracy: 0.9091\n",
      "Epoch 24/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.1519 - accuracy: 0.9621\n",
      "Epoch 25/50\n",
      "132/132 [==============================] - 3s 19ms/step - loss: 0.1644 - accuracy: 0.9470\n",
      "Epoch 26/50\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.0778 - accuracy: 0.9848\n",
      "Epoch 27/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 0.0862 - accuracy: 0.9773\n",
      "Epoch 28/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0669 - accuracy: 0.9848\n",
      "Epoch 29/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.0297 - accuracy: 1.0000\n",
      "Epoch 30/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 0.0352 - accuracy: 0.9924\n",
      "Epoch 31/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 0.0229 - accuracy: 1.0000\n",
      "Epoch 32/50\n",
      "132/132 [==============================] - 3s 20ms/step - loss: 0.0563 - accuracy: 0.9773\n",
      "Epoch 33/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0171 - accuracy: 1.0000\n",
      "Epoch 34/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 0.0244 - accuracy: 0.9924\n",
      "Epoch 35/50\n",
      "132/132 [==============================] - 2s 15ms/step - loss: 0.0204 - accuracy: 0.9924\n",
      "Epoch 36/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0104 - accuracy: 1.0000\n",
      "Epoch 37/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0097 - accuracy: 1.0000\n",
      "Epoch 38/50\n",
      "132/132 [==============================] - 3s 22ms/step - loss: 0.0069 - accuracy: 1.0000\n",
      "Epoch 39/50\n",
      "132/132 [==============================] - 2s 18ms/step - loss: 0.0064 - accuracy: 1.0000\n",
      "Epoch 40/50\n",
      "132/132 [==============================] - 2s 14ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 41/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0056 - accuracy: 1.0000\n",
      "Epoch 42/50\n",
      "132/132 [==============================] - 2s 17ms/step - loss: 0.0045 - accuracy: 1.0000\n",
      "Epoch 43/50\n",
      "132/132 [==============================] - 2s 16ms/step - loss: 0.0037 - accuracy: 1.0000\n",
      "Epoch 44/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0052 - accuracy: 1.0000\n",
      "Epoch 45/50\n",
      "132/132 [==============================] - 2s 13ms/step - loss: 0.0038 - accuracy: 1.0000\n",
      "Epoch 46/50\n",
      "132/132 [==============================] - 2s 19ms/step - loss: 0.0043 - accuracy: 1.0000\n",
      "Epoch 47/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 48/50\n",
      "132/132 [==============================] - 3s 21ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 49/50\n",
      "132/132 [==============================] - 3s 24ms/step - loss: 0.0034 - accuracy: 1.0000\n",
      "Epoch 50/50\n",
      "132/132 [==============================] - 3s 22ms/step - loss: 0.0039 - accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x28e83a5c848>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_indices = sentences_to_indices(X_train, word_to_index, max_len_train)\n",
    "Y_train_oh = convert_to_one_hot(y_train, c= 5)\n",
    "model.fit(X_train_indices, Y_train_oh, epochs = 50, batch_size = 32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56/56 [==============================] - 0s 4ms/step\n",
      "\n",
      "Test accuracy =  0.8928571343421936\n"
     ]
    }
   ],
   "source": [
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len=max_len_train)\n",
    "Y_test_oh = convert_to_one_hot(y_test, c= 5)\n",
    "loss, acc = model.evaluate(X_test_indices, Y_test_oh)\n",
    "print()\n",
    "print(\"Test accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected emoji:üòû prediction: work is hard\tüòÑ\n",
      "Expected emoji:üòû prediction: This girl is messing with me\t‚ù§Ô∏è\n",
      "Expected emoji:üç¥ prediction: any suggestions for dinner\tüòÑ\n",
      "Expected emoji:üòÑ prediction: you brighten my day\tüòû\n",
      "Expected emoji:üòû prediction: she is a bully\t‚ù§Ô∏è\n",
      "Expected emoji:üç¥ prediction: I did not have breakfast üòû\n"
     ]
    }
   ],
   "source": [
    "# This code allows you to see the mislabelled examples\n",
    "C = 5\n",
    "y_test_oh = np.eye(C)[y_test.reshape(-1)]\n",
    "X_test_indices = sentences_to_indices(X_test, word_to_index, max_len_train)\n",
    "pred = model.predict(X_test_indices)\n",
    "for i in range(len(X_test)):\n",
    "    x = X_test_indices\n",
    "    num = np.argmax(pred[i])\n",
    "    if(num != y_test[i]):\n",
    "        print('Expected emoji:'+ convert_to_emoji(y_test[i]) + ' prediction: '+ X_test[i] + convert_to_emoji(num).strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Congratulations We hope you are  happy  for accomplishment ! üòÑ\n"
     ]
    }
   ],
   "source": [
    "# Change the sentence below to see your prediction. Make sure all the words are in the Glove embeddings.  \n",
    "x_test = np.array([\"Congratulations We hope you are  happy  for accomplishment !\"])\n",
    "X_test_indices = sentences_to_indices(x_test, word_to_index, max_len_train)\n",
    "print(x_test[0] +' '+  convert_to_emoji(np.argmax(model.predict(X_test_indices))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
